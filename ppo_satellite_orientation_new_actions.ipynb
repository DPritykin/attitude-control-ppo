{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppo_satellite_orientation_new_actions",
      "provenance": [],
      "collapsed_sections": [
        "RHRt4sMVHqPg",
        "XJZVUK_pHqPj"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9g-wDw7HqPa"
      },
      "source": [
        "# Proximal Policy Optimization\n",
        "\n",
        "**Author:** [Ilias Chrysovergis](https://twitter.com/iliachry)<br>\n",
        "**Date created:** 2021/06/24<br>\n",
        "**Last modified:** 2021/06/24<br>\n",
        "**Description:** Implementation of a Proximal Policy Optimization agent for the CartPole-v0 environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxEogGtvHqPf"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This code example solves the TorqueDynamics environment using a Proximal Policy Optimization (PPO) agent.\n",
        "\n",
        "### Proximal Policy Optimization\n",
        "\n",
        "PPO is a policy gradient method and can be used for environments with either discrete or continuous action spaces.\n",
        "It trains a stochastic policy in an on-policy way. Also, it utilizes the actor critic method. The actor maps the\n",
        "observation to an action and the critic gives an expectation of the rewards of the agent for the observation given.\n",
        "Firstly, it collects a set of trajectories for each epoch by sampling from the latest version of the stochastic policy.\n",
        "Then, the rewards-to-go and the advantage estimates are computed in order to update the policy and fit the value function.\n",
        "The policy is updated via a stochastic gradient ascent optimizer, while the value function is fitted via some gradient descent algorithm.\n",
        "This procedure is applied for many epochs until the environment is solved.\n",
        "\n",
        "![Algorithm](https://i.imgur.com/rd5tda1.png)\n",
        "\n",
        "- [PPO Original Paper](https://arxiv.org/pdf/1707.06347.pdf)\n",
        "- [OpenAI Spinning Up docs - PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)\n",
        "\n",
        "### Note\n",
        "\n",
        "This code example uses Keras and Tensorflow v2. It is based on the PPO Original Paper,\n",
        "the OpenAI's Spinning Up docs for PPO, and the OpenAI's Spinning Up implementation of PPO using Tensorflow v1.\n",
        "\n",
        "[OpenAI Spinning Up Github - PPO](https://github.com/openai/spinningup/blob/master/spinup/algos/tf1/ppo/ppo.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHRt4sMVHqPg"
      },
      "source": [
        "## Libraries\n",
        "\n",
        "For this example the following libraries are used:\n",
        "\n",
        "1. `numpy` for n-dimensional arrays\n",
        "2. `tensorflow` and `keras` for building the deep RL PPO agent\n",
        "3. `gym` for getting everything we need about the environment\n",
        "4. `scipy.signal` for calculating the discounted cumulative sums of vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y78rKHSSHqPh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import gym\n",
        "import scipy.signal\n",
        "import time\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJZVUK_pHqPj"
      },
      "source": [
        "## Functions and class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyKokzpKHqPj"
      },
      "source": [
        "\n",
        "def discounted_cumulative_sums(x, discount):\n",
        "    # Discounted cumulative sums of vectors for computing rewards-to-go and advantage estimates\n",
        "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]\n",
        "\n",
        "\n",
        "class Buffer:\n",
        "    # Buffer for storing trajectories\n",
        "    def __init__(self, observation_dimensions, size, gamma=0.99, lam=0.95):\n",
        "        # Buffer initialization\n",
        "        self.observation_buffer = np.zeros(\n",
        "            (size, observation_dimensions), dtype=np.float32\n",
        "        )\n",
        "        self.action_buffer = np.zeros(size, dtype=np.int32)\n",
        "        self.advantage_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.reward_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.return_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.value_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.logprobability_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.gamma, self.lam = gamma, lam\n",
        "        self.pointer, self.trajectory_start_index = 0, 0\n",
        "\n",
        "    def store(self, observation, action, reward, value, logprobability):\n",
        "        # Append one step of agent-environment interaction\n",
        "        self.observation_buffer[self.pointer] = observation\n",
        "        self.action_buffer[self.pointer] = action\n",
        "        self.reward_buffer[self.pointer] = reward\n",
        "        self.value_buffer[self.pointer] = value\n",
        "        self.logprobability_buffer[self.pointer] = logprobability\n",
        "        self.pointer += 1\n",
        "\n",
        "    def finish_trajectory(self, last_value=0):\n",
        "        # Finish the trajectory by computing advantage estimates and rewards-to-go\n",
        "        path_slice = slice(self.trajectory_start_index, self.pointer)\n",
        "        rewards = np.append(self.reward_buffer[path_slice], last_value)\n",
        "        values = np.append(self.value_buffer[path_slice], last_value)\n",
        "\n",
        "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
        "\n",
        "        self.advantage_buffer[path_slice] = discounted_cumulative_sums(\n",
        "            deltas, self.gamma * self.lam\n",
        "        )\n",
        "        self.return_buffer[path_slice] = discounted_cumulative_sums(\n",
        "            rewards, self.gamma\n",
        "        )[:-1]\n",
        "\n",
        "        self.trajectory_start_index = self.pointer\n",
        "\n",
        "    def get(self):\n",
        "        # Get all data of the buffer and normalize the advantages\n",
        "        self.pointer, self.trajectory_start_index = 0, 0\n",
        "        advantage_mean, advantage_std = (\n",
        "            np.mean(self.advantage_buffer),\n",
        "            np.std(self.advantage_buffer),\n",
        "        )\n",
        "        self.advantage_buffer = (self.advantage_buffer - advantage_mean) / advantage_std\n",
        "        return (\n",
        "            self.observation_buffer,\n",
        "            self.action_buffer,\n",
        "            self.advantage_buffer,\n",
        "            self.return_buffer,\n",
        "            self.logprobability_buffer,\n",
        "        )\n",
        "\n",
        "\n",
        "def mlp(x, sizes, activation=tf.nn.relu, output_activation=None):\n",
        "    # Build a feedforward neural network\n",
        "    for size in sizes[:-1]:\n",
        "        x = layers.Dense(units=size, activation=activation)(x)\n",
        "    return layers.Dense(units=sizes[-1], activation=output_activation)(x)\n",
        "\n",
        "\n",
        "def logprobabilities(logits, a):\n",
        "    # Compute the log-probabilities of taking actions a by using the logits (i.e. the output of the actor)\n",
        "    logprobabilities_all = tf.nn.log_softmax(logits)\n",
        "    logprobability = tf.reduce_sum(\n",
        "        tf.one_hot(a, num_actions) * logprobabilities_all, axis=1\n",
        "    )\n",
        "    return logprobability\n",
        "\n",
        "\n",
        "# Sample action from actor\n",
        "@tf.function\n",
        "def sample_action(observation):\n",
        "    logits = actor(observation)\n",
        "    action = tf.squeeze(tf.random.categorical(logits, 1), axis=1)\n",
        "    return logits, action\n",
        "\n",
        "\n",
        "# Train the policy by maxizing the PPO-Clip objective\n",
        "@tf.function\n",
        "def train_policy(\n",
        "    observation_buffer, action_buffer, logprobability_buffer, advantage_buffer\n",
        "):\n",
        "\n",
        "    with tf.GradientTape() as tape:  # Record operations for automatic differentiation.\n",
        "        ratio = tf.exp(\n",
        "            logprobabilities(actor(observation_buffer), action_buffer)\n",
        "            - logprobability_buffer\n",
        "        )\n",
        "        min_advantage = tf.where(\n",
        "            advantage_buffer > 0,\n",
        "            (1 + clip_ratio) * advantage_buffer,\n",
        "            (1 - clip_ratio) * advantage_buffer,\n",
        "        )\n",
        "\n",
        "        policy_loss = -tf.reduce_mean(\n",
        "            tf.minimum(ratio * advantage_buffer, min_advantage)\n",
        "        )\n",
        "    policy_grads = tape.gradient(policy_loss, actor.trainable_variables)\n",
        "    policy_optimizer.apply_gradients(zip(policy_grads, actor.trainable_variables))\n",
        "\n",
        "    kl = tf.reduce_mean(\n",
        "        logprobability_buffer\n",
        "        - logprobabilities(actor(observation_buffer), action_buffer)\n",
        "    )\n",
        "    kl = tf.reduce_sum(kl)\n",
        "    return kl\n",
        "\n",
        "\n",
        "# Train the value function by regression on mean-squared error\n",
        "@tf.function\n",
        "def train_value_function(observation_buffer, return_buffer):\n",
        "    with tf.GradientTape() as tape:  # Record operations for automatic differentiation.\n",
        "        value_loss = tf.reduce_mean((return_buffer - critic(observation_buffer)) ** 2)\n",
        "    value_grads = tape.gradient(value_loss, critic.trainable_variables)\n",
        "    value_optimizer.apply_gradients(zip(value_grads, critic.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eclr-wmlHqPk"
      },
      "source": [
        "## Hyperparameters and others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L9RbWNAHqPl"
      },
      "source": [
        "# Hyperparameters of the PPO algorithm\n",
        "steps_per_epoch = 500\n",
        "epochs = 1000\n",
        "gamma = 0.99\n",
        "clip_ratio = 0.2\n",
        "policy_learning_rate = 3e-4\n",
        "value_function_learning_rate = 1e-3\n",
        "train_policy_iterations = 80\n",
        "train_value_iterations = 80\n",
        "lam = 0.95\n",
        "target_kl = 0.01\n",
        "hidden_sizes = (400, 300)\n",
        "\n",
        "# True if you want to render the environment\n",
        "render = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyghzEOgQJ3w"
      },
      "source": [
        "def plot_euler_angles(t, roll, pitch, yaw, filename=None):\n",
        "  fig1 = plt.figure(figsize=(8,8))\n",
        "  ax1 = fig1.add_subplot(1,1,1)\n",
        "  ax1.set_title(\"Euler Angles\")\n",
        "  ax1.plot(t, roll, label = 'roll', color = 'red')\n",
        "  ax1.plot(t, pitch, label = 'pitch', color = 'green')\n",
        "  ax1.plot(t, yaw, label = 'yaw', color = 'blue')\n",
        "  ax1.set_ybound(-10, 10)\n",
        "  ax1.set_ylabel(r'angles, [deg]')\n",
        "  ax1.set_xlabel(r't, [s]')\n",
        "  ax1.grid(True)\n",
        "  ax1.legend()\n",
        "  fig1.show()\n",
        "  if filename is not None:\n",
        "    fig1.savefig(f'{filename}')\n",
        "\n",
        "def plot_euler_angles_radial(t, roll, pitch, yaw, filename=None):\n",
        "  fig1 = plt.figure(figsize=(8,8))\n",
        "  ax1 = fig1.add_subplot(1,1,1, polar=True)\n",
        "  ax1.set_title(\"Euler Angles\")\n",
        "  ax1.plot(roll, t, label = 'roll', color = 'red')\n",
        "  ax1.plot(pitch, t, label = 'pitch', color = 'green')\n",
        "  ax1.plot(yaw, t, label = 'yaw', color = 'blue')\n",
        "  #ax1.set_ylabel(r'angles, [deg]')\n",
        "  #ax1.set_xlabel(r't, [s]')\n",
        "  ax1.grid(True)\n",
        "  ax1.legend()\n",
        "  fig1.show()\n",
        "  if filename is not None:\n",
        "    fig1.savefig(f'{filename}')\n",
        "\n",
        "def plot_phase_diagram(roll, pitch, yaw, omega_, filename=None):\n",
        "  fig2 = plt.figure(figsize=(8,8))\n",
        "  ax2 = fig2.add_subplot(1,1,1)\n",
        "  ax2.set_title(\"Phase diagram\")\n",
        "  ax2.plot(roll, omega_[0], label = 'roll', color = 'red')\n",
        "  ax2.plot(pitch, omega_[1], label = 'pitch', color = 'green')\n",
        "  ax2.plot(yaw, omega_[2], label = 'yaw', color = 'blue')\n",
        "  ax2.plot([0],[0], 'o', markersize=8 , label='Destination', color = 'magenta')\n",
        "  ax2.set_xlabel(r'$\\alpha$')\n",
        "  ax2.set_ylabel(r'$\\omega$')\n",
        "  ax2.legend()\n",
        "  ax2.grid()\n",
        "  fig2.show()\n",
        "  if filename is not None:\n",
        "    fig2.savefig(f'{filename}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grBwDNIHKmkA"
      },
      "source": [
        "# Вспомогательные функции\n",
        "\n",
        "def normalize(obj):\n",
        "\n",
        "    return obj / np.linalg.norm(obj)\n",
        "\n",
        "\n",
        "def cross_product(a, b):\n",
        "\n",
        "    def check_dimensions(vec, string):\n",
        "\n",
        "        if vec.ndim != 1:\n",
        "            raise Exception(\"The {} input is not a vector\".format(string))\n",
        "        if len(vec) != 3:\n",
        "            raise Exception(\"Wrong number of coordinates in the {0} vector: {1}, should be 3\".format(string, len(vec)))\n",
        "\n",
        "    check_dimensions(a, 'first')\n",
        "    check_dimensions(b, 'second')\n",
        "\n",
        "    return np.array([a[1]*b[2]-a[2]*b[1], a[2]*b[0]-a[0]*b[2], a[0]*b[1] - a[1]*b[0]])\n",
        "\n",
        "def quat_product(q1, q2):\n",
        "\n",
        "    def check_dimensions(q, string):\n",
        "\n",
        "        if q.ndim != 1:\n",
        "            raise Exception(\"The {} input is not a quaternion\".format(string))\n",
        "        if len(q) != 4:\n",
        "            raise Exception(\"Wrong number of coordinates in the {0} quaternion: {1}, should be 4\".format(string, len(q)))\n",
        "\n",
        "    check_dimensions(q1, 'first')\n",
        "    check_dimensions(q2, 'second')\n",
        "\n",
        "    q = np.zeros(4)\n",
        "    q[0] = q1[0] * q2[0] - q1[1:].dot(q2[1:])\n",
        "    q[1:] = q1[0] * q2[1:] + q2[0] * q1[1:] + cross_product(q1[1:], q2[1:])\n",
        "\n",
        "    return q\n",
        "\n",
        "def rotate_vec_with_quat(q, vec):\n",
        "\n",
        "    def check_dimensions(obj, is_quat):\n",
        "\n",
        "        if obj.ndim != 1:\n",
        "            raise Exception(\"Not a {}\".format('quaternion' * is_quat + 'vector' * (1 - is_quat)))\n",
        "        if len(obj) != (3 + 1 * is_quat):\n",
        "            raise Exception(\"Wrong number of coordinates in the {0}: {1}, should be {2}\"\n",
        "                            .format('quaternion' * is_quat + 'vector' * (1 - is_quat), len(obj), 3 + 1 * is_quat))\n",
        "\n",
        "    check_dimensions(q, True)\n",
        "    check_dimensions(vec, False)\n",
        "\n",
        "    q = quat_conjugate(q)\n",
        "\n",
        "    qxvec = cross_product(q[1:], vec)\n",
        "\n",
        "    return q[1:].dot(vec) * q[1:] + q[0]**2. * vec + 2. * q[0] * qxvec + cross_product(q[1:], qxvec)\n",
        "\n",
        "def quat2rpy(q0, q1, q2, q3):\n",
        "\n",
        "    roll = np.arctan2(2. * (q0 * q1 + q2 * q3), 1. - 2. * (q1**2 + q2**2))\n",
        "    pitch = np.arcsin(2. * (q0 * q2 - q1 * q3))\n",
        "    yaw = np.arctan2(2. * (q0 * q3 + q1 * q2), 1. - 2. * (q2**2 + q3**2))\n",
        "\n",
        "    return [roll, pitch, yaw]\n",
        "\n",
        "def quat2rpy_deg(q0, q1, q2, q3):\n",
        "\n",
        "    roll = np.arctan2(2. * (q0 * q1 + q2 * q3), 1. - 2. * (q1**2 + q2**2))*180/np.pi\n",
        "    pitch = np.arcsin(2. * (q0 * q2 - q1 * q3))*180/np.pi\n",
        "    yaw = np.arctan2(2. * (q0 * q3 + q1 * q2), 1. - 2. * (q2**2 + q3**2))*180/np.pi\n",
        "\n",
        "    return [roll, pitch, yaw]\n",
        "\n",
        "def quat_conjugate(q):\n",
        "\n",
        "    q_new = np.copy(q)\n",
        "    q_new[1:] = q_new[1:] * -1.\n",
        "\n",
        "    return q_new\n",
        "\n",
        "def rhs(t, x, sat, action):\n",
        "\n",
        "    quat = x[:4] / np.linalg.norm(x[:4])\n",
        "    omega = x[4:7]       \n",
        "\n",
        "    x_dot = np.zeros(10)\n",
        "\n",
        "    x_dot[0] = -0.5 * quat[1:].dot(omega)\n",
        "    x_dot[1:4] = 0.5 * (quat[0] * omega + cross_product(quat[1:],omega))\n",
        "\n",
        "    #print(sat.J_inv)\n",
        "\n",
        "    tmp3 = (action - cross_product(omega, sat.J.dot(omega) + x_dot[7:10]).reshape(3, 1)).reshape(3)\n",
        "    x_dot[4:7] = sat.J_inv.dot(tmp3)\n",
        "    x_dot[7:] = -action.reshape(3)\n",
        "    return x_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgV_YTzdKJUy"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "sat = SimpleNamespace()\n",
        "sat.J = np.diag(np.array([3, 4, 5]))\n",
        "sat.J_inv = np.linalg.inv(sat.J)\n",
        "\n",
        "class TorqueDynamics(gym.Env):\n",
        "  observation_space = gym.spaces.Box(-1, 1, shape=(10,))\n",
        "\n",
        "  \n",
        "  def __init__(self, dt, q_req, add_9=0.25):\n",
        "    self.state = None\n",
        "    self.dt = dt\n",
        "    self.q_req = q_req\n",
        "    self.q_req_conj = quat_conjugate(self.q_req)\n",
        "    self.w_req = np.zeros(3)\n",
        "    self.history = []\n",
        "    self.t = []\n",
        "    self.action_space = self.init_actions()\n",
        "    self.q_prev = None\n",
        "    self.add_9 = add_9\n",
        "\n",
        "  @staticmethod\n",
        "  def init_actions():\n",
        "    a = np.linspace(-1, 1, 21)\n",
        "    a1 = a/10\n",
        "    a2 = a/100\n",
        "    a = np.concatenate((a, a1, a2))\n",
        "    a = np.unique(a.round(10))\n",
        "    a = a[a>=-0.5]\n",
        "    a = a[a<=0.5]\n",
        "\n",
        "    s = a.shape\n",
        "    a = np.vstack((a, np.zeros(s)))\n",
        "    a = np.vstack((a, np.zeros(s)))\n",
        "    a = a.T\n",
        "    aroll1 = np.roll(a, 1)\n",
        "    aroll2 = np.roll(a, 2)\n",
        "    a = np.concatenate((a, aroll1))\n",
        "    a = np.concatenate((a, aroll2))\n",
        "    a = np.unique(a, axis=0)\n",
        "    return a\n",
        "\n",
        "  def reset(self, state=None):\n",
        "    if state is not None:\n",
        "      self.state = state\n",
        "    else:\n",
        "      self.state = self.observation_space.sample()\n",
        "      phi = self.state[0] * np.pi \n",
        "      self.state[0] = np.cos(phi / 2)\n",
        "      self.state[1:4] = normalize(self.state[1:4]) * np.sin(phi / 2)\n",
        "      self.state[4:] = 0\n",
        "    self.history = [self.state]\n",
        "    self.t = [0]\n",
        "    self.q_prev = self.state[:4]\n",
        "    return self.state\n",
        "\n",
        "  @staticmethod\n",
        "  def r_a(phi, q_current, q_prev):\n",
        "    return np.exp(-phi/(0.14*2*np.pi)) if q_current > q_prev else np.exp(-phi/(0.14*2*np.pi)) - 1\n",
        "\n",
        "  def r_t(self, reward, phi):\n",
        "    return reward + 9 if phi <= self.add_9 else reward\n",
        "\n",
        "  def step(self, action):\n",
        "    t0 = 0\n",
        "    tf = self.dt\n",
        "    x_0 = self.state\n",
        "    if isinstance(action, int) or isinstance(action, np.int64):\n",
        "      action = self.action_space[action].reshape(3,1)\n",
        "    \n",
        "\n",
        "    sol = solve_ivp(lambda t, x: rhs(t, x, sat, action), (t0,tf), x_0)#, t_eval=t_eval)\n",
        "    x = sol.y.T\n",
        "    t = sol.t[1:]\n",
        "    observation = x[-1]\n",
        "    observations = normalize(observation)\n",
        "    time_ = self.t[-1] + self.dt\n",
        "    self.state = observation\n",
        "    self.history.append(observation)\n",
        "    self.t.append(time_)\n",
        "\n",
        "    # calculating reward:\n",
        "    q_current = observation[:4]\n",
        "    q_error = quat_product(self.q_req_conj, q_current)\n",
        "    q_error = np.clip(q_error, -1, 1)\n",
        "    w_current = observation[4:7]\n",
        "    #print('q_error', q_error)\n",
        "    if q_error[0] < -1 or q_error[0] > 1:\n",
        "      print('wtf, ', self.state)\n",
        "    phi = 2*np.arccos(q_error[0])\n",
        "    r_inter = self.r_a(phi, q_current[0], self.q_prev[0])\n",
        "    r1 = self.r_t(r_inter, phi)\n",
        "    # r2 = -np.sum(np.abs(observation[4:7]))\n",
        "    # Qreward = np.exp(-0.1 * np.linalg.norm(q_current - self.q_req))\n",
        "    # Wreward = np.exp(-0.1 * np.linalg.norm(w_current - self.w_req))\n",
        "    # reward = Qreward * Wreward\n",
        "    # reward = self.r_t(reward, phi)\n",
        "    reward = r1# + 10 * r2\n",
        "\n",
        "    #print('rewards', r1, r2)\n",
        "    self.q_prev = q_current\n",
        "\n",
        "    q_req_ext = np.concatenate([self.q_req, self.w_req])\n",
        "    done = np.linalg.norm(observation[:7] - q_req_ext) < 1e-4\n",
        "    \n",
        "    info = dict()\n",
        "    info['x'] = self.history\n",
        "    info['t'] = self.t\n",
        "    return observation, reward, done, info\n",
        "  \n",
        "  def render(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4k0dL4KHqPm"
      },
      "source": [
        "## Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1iWcjWEHqPm"
      },
      "source": [
        "# Initialize the environment and get the dimensionality of the\n",
        "# observation space and the number of possible actions\n",
        "env = TorqueDynamics(0.1, np.array([1, 0, 0, 0]), 0.05)\n",
        "observation_dimensions = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.shape[0]\n",
        "\n",
        "# Initialize the buffer\n",
        "buffer = Buffer(observation_dimensions, steps_per_epoch)\n",
        "\n",
        "# Initialize the actor and the critic as keras models\n",
        "observation_input = keras.Input(shape=(observation_dimensions,), dtype=tf.float32)\n",
        "logits = mlp(observation_input, list(hidden_sizes) + [num_actions], tf.nn.relu, None)\n",
        "actor = keras.Model(inputs=observation_input, outputs=logits)\n",
        "value = tf.squeeze(\n",
        "    mlp(observation_input, list(hidden_sizes) + [1], tf.nn.relu, None), axis=1\n",
        ")\n",
        "critic = keras.Model(inputs=observation_input, outputs=value)\n",
        "\n",
        "# Initialize the policy and the value function optimizers\n",
        "policy_optimizer = keras.optimizers.Adam(learning_rate=policy_learning_rate)\n",
        "value_optimizer = keras.optimizers.Adam(learning_rate=value_function_learning_rate)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdMXapmNHqPn"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ5mF2vaHqPn"
      },
      "source": [
        "def train(epochs, add_9, start=None):\n",
        "# Iterate over the number of epochs\n",
        "  print('starting training with', epochs, 'epochs')\n",
        "  buffer = Buffer(observation_dimensions, steps_per_epoch)\n",
        "  env = TorqueDynamics(0.1, np.array([1, 0, 0, 0]), add_9)\n",
        "  # Initialize the observation, episode return and episode length\n",
        "  observation, episode_return, episode_length = env.reset(start), 0, 0\n",
        "\n",
        "  returns = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      # Initialize the sum of the returns, lengths and number of episodes for each epoch\n",
        "      sum_return = 0\n",
        "      sum_length = 0\n",
        "      num_episodes = 0\n",
        "\n",
        "      # Iterate over the steps of each epoch\n",
        "      for t in range(steps_per_epoch):\n",
        "          if render:\n",
        "              env.render()\n",
        "\n",
        "          # Get the logits, action, and take one step in the environment\n",
        "          observation = observation.reshape(1, -1)\n",
        "          logits, action = sample_action(observation)\n",
        "          #print(type(action[0].numpy()))\n",
        "          observation_new, reward, done, info = env.step(action[0].numpy())\n",
        "          episode_return += reward\n",
        "          episode_length += 1\n",
        "\n",
        "          # Get the value and log-probability of the action\n",
        "          value_t = critic(observation)\n",
        "          logprobability_t = logprobabilities(logits, action)\n",
        "\n",
        "          # Store obs, act, rew, v_t, logp_pi_t\n",
        "          buffer.store(observation, action, reward, value_t, logprobability_t)\n",
        "\n",
        "          # Update the observation\n",
        "          observation = observation_new\n",
        "\n",
        "          # Finish trajectory if reached to a terminal state\n",
        "          terminal = done\n",
        "          if terminal or (t == steps_per_epoch - 1):\n",
        "              last_value = 0 if done else critic(observation.reshape(1, -1))\n",
        "              buffer.finish_trajectory(last_value)\n",
        "              sum_return += episode_return\n",
        "              sum_length += episode_length\n",
        "              num_episodes += 1\n",
        "              observation, episode_return, episode_length = env.reset(start), 0, 0\n",
        "\n",
        "      # Get values from the buffer\n",
        "      (\n",
        "          observation_buffer,\n",
        "          action_buffer,\n",
        "          advantage_buffer,\n",
        "          return_buffer,\n",
        "          logprobability_buffer,\n",
        "      ) = buffer.get()\n",
        "\n",
        "      # Update the policy and implement early stopping using KL divergence\n",
        "      for _ in range(train_policy_iterations):\n",
        "          kl = train_policy(\n",
        "              observation_buffer, action_buffer, logprobability_buffer, advantage_buffer\n",
        "          )\n",
        "          if kl > 1.5 * target_kl:\n",
        "              # Early Stopping\n",
        "              break\n",
        "\n",
        "      # Update the value function\n",
        "      for _ in range(train_value_iterations):\n",
        "          train_value_function(observation_buffer, return_buffer)\n",
        "\n",
        "      # Print mean return and length for each epoch\n",
        "      print(\n",
        "          f\" Epoch: {epoch + 1}. Mean Return: {sum_return / num_episodes}. Mean Length: {sum_length / num_episodes}\"\n",
        "      )\n",
        "      returns.append(sum_return / num_episodes)\n",
        "  return returns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E1Q3xHBamXF",
        "outputId": "48ce4f9e-2e36-4a47-874c-a3a3d6b9d027"
      },
      "source": [
        "iterations = 20\n",
        "reward_thresh = 0.003\n",
        "tries = 50\n",
        "\n",
        "for i in range(tries):\n",
        "  print(f'Run #{i}. The \"+9\" threshold is {reward_thresh}')\n",
        "  mean_ret = train(iterations, reward_thresh)\n",
        "  mean_ret = np.median(mean_ret)\n",
        "  print(f'Current batch mean is {mean_ret}')\n",
        "  print('-'*10)\n",
        "  if mean_ret > 1000 and reward_thresh > 0.004:\n",
        "    reward_thresh *= 0.8 - 3*(mean_ret - 1000)/40000 # linear from (1000, 0.8) to (5000, 0.5)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run #0. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 2498.63782235192. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1877.4797560843815. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1105.719911005354. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1636.5485039853513. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 232.1062189925846. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1891.635612410122. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 741.2152047050454. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2722.249085863469. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1881.3228542110708. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2045.0377163248352. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 1433.7076455588033. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 2113.8160675729973. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 504.04568075080425. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2497.3098718886895. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1782.1523906371854. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1005.4705958866747. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2007.1131878714202. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2870.0417286905085. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2486.8160604892396. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2319.455312396751. Mean Length: 500.0\n",
            "Current batch mean is 1886.4792333105963\n",
            "----------\n",
            "Run #1. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 262.8001614858963. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 2196.136750380823. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1857.9648089039192. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 174.67907477348498. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 897.9517302215372. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 255.3073090100945. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1259.1070809430375. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 241.11565769991762. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 375.8881879132899. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1003.2321357610552. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2054.7000029165865. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 103.49754880730005. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1042.6135494499697. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 330.4992896869546. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1971.7778387596275. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2317.0600411889486. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1909.8287185991146. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2664.2040005566937. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 206.83325116733155. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 919.3863680058538. Mean Length: 500.0\n",
            "Current batch mean is 961.3092518834545\n",
            "----------\n",
            "Run #2. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 832.1075719889446. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 2475.862869549951. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 727.6525263752784. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1822.5448137216624. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 170.3194891940463. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1553.3188135835346. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1725.2615560182649. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 304.3160852650898. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1007.0301970444926. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 383.32689586792685. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 804.135447145593. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1850.065202295418. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1289.0409396356042. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1198.7060474205373. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1160.4223599171967. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2218.714645040627. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 249.86081189879644. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2186.9331677401665. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1753.0043980519258. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 926.114442009413. Mean Length: 500.0\n",
            "Current batch mean is 1179.5642036688669\n",
            "----------\n",
            "Run #3. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 548.5489126828832. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 212.5166980253027. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 2405.0156260000394. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1763.8015633089024. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 291.5619971207604. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 296.003141793864. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 108.9839046438507. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 70.8169051281978. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 722.2322580573216. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 238.89572720132884. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 226.70974385138203. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 197.5117355865717. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 197.73581378797246. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1840.8179456662413. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1207.8399950749927. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 237.26391577274433. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2188.500539749417. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2032.6356871159328. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2962.2474933274393. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2900.239464571916. Mean Length: 500.0\n",
            "Current batch mean is 422.27602723837356\n",
            "----------\n",
            "Run #4. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 270.1067546826449. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 292.6732281360862. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 2012.0981728530576. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 2095.1171229307884. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2225.9544844082216. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 2997.008547059928. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 2174.2904864284087. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 263.64460052340854. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 565.6324976396659. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 192.67373789085042. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 1992.086271445104. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 235.9171091678968. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1443.2284591237728. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1732.0449225323148. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 71.48326451359968. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 220.8602432606131. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1646.375074721058. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1412.3434240364238. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2596.5288925759473. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2211.7839829619047. Mean Length: 500.0\n",
            "Current batch mean is 1544.8017669224155\n",
            "----------\n",
            "Run #5. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 147.22865133987844. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1741.4929635424937. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1051.2609551074645. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1726.3753655198816. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2697.778113411773. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1495.6085943016303. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 382.5151410297011. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 100.86919160749487. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 248.66787480698886. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2416.44375990326. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 735.6862389458068. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 138.6124212115126. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 303.85260040120295. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 217.04603299476858. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 233.9775594052425. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 106.32674684694568. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 215.80591374353438. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 651.138722942409. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 254.23012660184125. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 253.61697113895568. Mean Length: 500.0\n",
            "Current batch mean is 279.0413635015221\n",
            "----------\n",
            "Run #6. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 773.6509979070722. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 297.8833585126742. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1757.8901276597492. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 546.844243412576. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2018.191007808478. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 669.0964069943175. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 250.54967547626032. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1510.6602045989778. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 147.5892215895563. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 199.46573575716204. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 216.16524580705283. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 222.41040227677638. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1024.0298701866502. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1585.3752486324095. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 145.2234234705938. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 153.84689382745174. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 154.40383204412143. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 127.05934299423058. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 258.1716711171576. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 257.3156482084496. Mean Length: 500.0\n",
            "Current batch mean is 257.74365966280357\n",
            "----------\n",
            "Run #7. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 145.02698991178278. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 225.70053088391325. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 243.20989416264322. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 265.1299494503841. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 284.16321509063454. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 280.8049248366763. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 231.7115589060363. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 225.15362487789386. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 221.6218425433205. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 223.92193984947858. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 273.3586321229381. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 275.31942443870884. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 271.53233522843425. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 299.95400581232275. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 431.3322263475305. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 319.55888171126094. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 228.21440172417647. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 266.0239457363909. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 214.55561038800911. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 198.43159043818085. Mean Length: 500.0\n",
            "Current batch mean is 254.16992180651368\n",
            "----------\n",
            "Run #8. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 526.9877680930758. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 235.1332710696613. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 483.5767143021134. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 221.1092186588631. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 236.59245763226238. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 256.1509057170363. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 235.3264356605385. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2120.838505004508. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 181.5143809708147. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 271.2021642739199. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 452.06235170328495. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 2420.9856449474414. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1855.4585147877285. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 514.4248257132604. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1982.8713868637517. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1989.1074701638784. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 191.1820973553326. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 145.54160731221327. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 142.83497785972457. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 207.06340874347373. Mean Length: 500.0\n",
            "Current batch mean is 263.6765349954781\n",
            "----------\n",
            "Run #9. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 247.550725196188. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1054.9185577287444. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 776.1732078473856. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1401.6065136917857. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 414.28253764753134. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 461.32456558768615. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 236.6419151811477. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1294.6418841163795. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1113.8790678643632. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 254.7819105555028. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 854.3761050944883. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 226.88579649295383. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 310.1411552693442. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 744.4622589727262. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 260.5394439126922. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 198.40774841078607. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2100.009263488509. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 336.3652505407461. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 468.7909102043949. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 315.49461724633505. Mean Length: 500.0\n",
            "Current batch mean is 437.8035516176087\n",
            "----------\n",
            "Run #10. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 527.733313644123. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 869.7823262202871. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 390.63197132159047. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 2303.8612683167985. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 134.35339875685776. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 479.5155331971198. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 872.5700570213586. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 242.45087837168413. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 195.31420933091357. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 147.63219842200272. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 653.5003135160042. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 869.673001903285. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 327.4834671115974. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1385.9410064502974. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 104.20337332784639. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 475.3820729952792. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 114.996017549459. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 562.8811407897691. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 67.52358350988376. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 128.14902426816369. Mean Length: 500.0\n",
            "Current batch mean is 433.00702215843484\n",
            "----------\n",
            "Run #11. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1156.5169833550583. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 171.2543647644105. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 146.272758208553. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 238.94549055619558. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1120.1735760608253. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1873.807990994599. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 384.4402318091782. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 393.7149178042468. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1034.3130370626632. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 3054.205769059829. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 146.4742883116623. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 231.61184770358952. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 220.02766560901472. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 315.334757472291. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 221.98752290545002. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 171.51110180799748. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 339.584479648185. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 191.35979719054077. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 993.0256765664835. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1631.654742325203. Mean Length: 500.0\n",
            "Current batch mean is 327.459618560238\n",
            "----------\n",
            "Run #12. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1300.602335766293. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 260.53843556237825. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 165.0458492427238. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 331.90170581939805. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 190.00841519088715. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 222.7957940056054. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1282.0444746858698. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 186.08418826404008. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2172.182757550754. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 176.07590049813834. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 286.8158229362129. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 487.6534221361809. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 602.5507598441086. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 790.0737615781226. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 242.79766023874498. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 223.23221330737027. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 293.40348755352414. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2105.3795924338506. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 249.33687992917825. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2137.611952342599. Mean Length: 500.0\n",
            "Current batch mean is 290.1096552448685\n",
            "----------\n",
            "Run #13. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1396.2490324389948. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1716.8452095543398. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1581.3777440806523. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 531.1741687541422. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1411.404564570818. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 248.58948608616714. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 523.4679664696313. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 394.5569132406462. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 229.51255870989118. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2877.7483635174467. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 913.4628360857831. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1101.3741343136196. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 490.9718016053915. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 228.52837369708402. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 211.59839609716258. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 550.071211316124. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1509.9754937035582. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 706.2027857322729. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2659.4652753283094. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 230.5658928529557. Mean Length: 500.0\n",
            "Current batch mean is 628.1369985241985\n",
            "----------\n",
            "Run #14. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 2051.3840329895174. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1047.6145646183684. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 247.78738844959696. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 90.66210697784831. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 203.32842257082348. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1621.205088328772. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1903.5758527060923. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2702.275722343597. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 180.57968168579356. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1648.1627336304236. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 241.36247472061768. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1002.8544864645545. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 210.11177301792316. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1103.9821714655939. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 202.34250102424812. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 311.45863096162066. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 69.04191427115387. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 239.3462940913604. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 142.81891977338637. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1417.9661037042633. Mean Length: 500.0\n",
            "Current batch mean is 279.6230097056088\n",
            "----------\n",
            "Run #15. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 236.03700834321654. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 408.7374154546802. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 263.47204410576495. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 717.2166012524821. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 225.30773152930504. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 274.8558982726687. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 331.2650241201132. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 223.37455717583364. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 156.25573057726487. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 286.84400789908995. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 229.7242427063029. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 287.2754587886344. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 277.7418473506715. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 285.3076681640301. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 263.7190762641696. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 439.317134704771. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 878.3247517972236. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1246.681187060499. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2231.132260890671. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 197.22204419084886. Mean Length: 500.0\n",
            "Current batch mean is 281.5247577573508\n",
            "----------\n",
            "Run #16. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 874.6005751779071. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1559.7333646666916. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 234.88876935398008. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 190.9751651712138. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1263.3468009089108. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1440.2296379171205. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 2146.5760093183694. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 87.9059894633005. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 253.0238200922932. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 258.8355003172229. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 216.75513291466217. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 566.5654278690125. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 569.9698726094518. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2139.8632548573796. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 985.5773554575609. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 209.43795933137457. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 259.7668759436113. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 326.93017187715105. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 185.80739856477683. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 159.6735772021658. Mean Length: 500.0\n",
            "Current batch mean is 293.3485239103812\n",
            "----------\n",
            "Run #17. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 219.7353281855185. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 732.7548347156646. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 178.0887250681454. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1565.662992723885. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 232.61415086568672. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1418.2315140597323. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 671.7295127708004. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2460.8214734117923. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 38.62106981651602. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 226.2305669397144. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 255.61807695995142. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 487.93234124701394. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 578.5905833274713. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 576.2845356678258. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 268.52366790066657. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 146.06040405763747. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1624.3229181019115. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 646.1802979960848. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 175.36364771962053. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1267.765223662598. Mean Length: 500.0\n",
            "Current batch mean is 532.1084384574199\n",
            "----------\n",
            "Run #18. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 252.82361897214133. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1385.9661031159103. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 250.39244338605457. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1201.3027994010806. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 351.2100727554672. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 235.4737812685096. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 257.65362051003314. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1916.4525393666042. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 213.7707371301487. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2051.5311682149513. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2211.5500058901584. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 415.1538319148822. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 569.1116778814385. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 179.4478734166552. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 255.4229151849259. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1812.3698848992574. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 511.9557416692988. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1116.7502736346994. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 294.22284631074837. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1162.0622798486097. Mean Length: 500.0\n",
            "Current batch mean is 463.55478679209045\n",
            "----------\n",
            "Run #19. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 687.779042515079. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1775.8618033535497. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 502.58097154560056. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 299.8889297183117. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 207.0045710027787. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 208.9720322086173. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 133.64233337083155. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2042.9422406603721. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1038.5776719981216. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1751.0301686252997. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 476.01434628596934. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 209.97213087851662. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 254.84791929703397. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 618.8814844627389. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 748.3077179637812. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2871.7590366465565. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2416.2708467364405. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 151.6279690919874. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 247.6896628442775. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 277.9430935459006. Mean Length: 500.0\n",
            "Current batch mean is 489.29765891578495\n",
            "----------\n",
            "Run #20. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 277.21264838321093. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 159.81822748466803. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 155.32077426013845. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 146.93568425307163. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 246.95939979800744. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 260.8704027713492. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 235.56549837404032. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 548.6815123160314. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 507.48480073314926. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 697.8324598727661. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 408.84155986612916. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 270.48372369480535. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 130.15967666332406. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 282.85793486057105. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 118.7980213946511. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 671.5774034474584. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 893.4928731128659. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 234.08106055919328. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1184.5688096040012. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2811.8612427164076. Mean Length: 500.0\n",
            "Current batch mean is 273.84818603900817\n",
            "----------\n",
            "Run #21. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1048.6929560019064. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 3110.979493911888. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 560.1787595945477. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1654.962392321473. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 51.21179012034998. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1601.020357487186. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1457.9689902647256. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 168.2038916512132. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 184.8090507998079. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 243.1598428397047. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 417.96707936877186. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 199.99597900180086. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 280.1058854932838. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1189.4226457018049. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1281.176654410269. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 936.9244444324812. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 299.3585280274415. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 491.4348495826799. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 233.48534816159895. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2268.2442647143357. Mean Length: 500.0\n",
            "Current batch mean is 525.8068045886138\n",
            "----------\n",
            "Run #22. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 197.2078992279124. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 683.1311713069595. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 708.5459981363089. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 230.86109953457685. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 243.7033124083998. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 247.88408424017516. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 571.9734906948248. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1562.1257901066408. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2539.256191403513. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 222.54614467325732. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2591.4802203922677. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 206.9161865439715. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 874.6817596699489. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 862.3548574991836. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 188.00866523616. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2409.4206373420147. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 352.5281473838264. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 924.239121872135. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1772.895490560044. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1995.5469132142355. Mean Length: 500.0\n",
            "Current batch mean is 695.8385847216341\n",
            "----------\n",
            "Run #23. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 98.20848800812648. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 102.41031197046698. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 121.83811123598106. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1386.2327969614464. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2041.377298153268. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1359.9577980170711. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1288.7579171040145. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2411.279921470138. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 181.8125401852292. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1528.2141130066063. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2660.9556320463435. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 535.6864643403585. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 2299.067388436399. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1580.8460161359405. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 414.8721650774532. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 277.17437214049795. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1662.12707782031. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 246.6877401425161. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 893.2392807182889. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 260.9003172615404. Mean Length: 500.0\n",
            "Current batch mean is 1090.9985989111517\n",
            "----------\n",
            "Run #24. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1436.5399467437117. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 115.40100184749714. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 146.6960781487816. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 265.5326781809249. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 614.4001960152334. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 170.25218781265798. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 765.6164371202997. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 386.6808421285222. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 705.0147373679172. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2111.3590525129557. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 119.41428388450008. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 264.05329359636744. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 184.11949642750068. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 662.054591302055. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 220.88162471869902. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 210.02672940685014. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 224.5479732749193. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 493.8771630474082. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1790.9913525043005. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1009.182529127873. Mean Length: 500.0\n",
            "Current batch mean is 326.1067601547236\n",
            "----------\n",
            "Run #25. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 245.31808172821505. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1437.9142368337145. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 2425.4486037738225. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1826.954662354459. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 198.00554842885816. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 2872.5825777360124. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 125.80051613310792. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 723.1683311663973. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 387.72265951718947. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 238.08192845009924. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 270.48257304226746. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 213.93867606044248. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 259.79625788581023. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 98.7529459975961. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 316.7188139200011. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 258.127958591331. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 302.5906166099782. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 236.38188426650845. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 366.8421833312329. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1183.6585033629422. Mean Length: 500.0\n",
            "Current batch mean is 286.53659482612284\n",
            "----------\n",
            "Run #26. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 427.21799389315714. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 431.53427742962884. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 87.96896137916215. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 835.4869046847853. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 269.96735846713324. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 643.5535138436369. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1275.0363951770407. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 190.8549617687598. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 252.39961888406899. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 195.94445750539083. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 192.88631179197537. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 901.3623190122141. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 735.5576750791224. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2129.238511657232. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 363.3064403193098. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1782.0585562909937. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 244.39554616378842. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 264.419366126629. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 194.96704928410884. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1002.4473429282009. Mean Length: 500.0\n",
            "Current batch mean is 395.2622171062335\n",
            "----------\n",
            "Run #27. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1410.8267259275226. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 2085.7745062105296. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1914.2898461121436. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 272.99842256279015. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 323.17716367288364. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 256.14636499507554. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 283.1283289491155. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 125.61914595273672. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1816.2764909371967. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 982.8192831916213. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 1463.2893075069076. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 167.15220137527314. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 2324.7484486715366. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2010.6868373483821. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 3007.7903622585754. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2274.6614487795373. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 262.09117409371316. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 750.0101334206548. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 218.28696258913712. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 278.0624334947197. Mean Length: 500.0\n",
            "Current batch mean is 866.414708306138\n",
            "----------\n",
            "Run #28. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 403.58833304908035. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 112.51209156134742. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 952.2709929470067. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1045.4522209883125. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1720.1497290939483. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 145.94975834155824. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 2070.4708789316005. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1593.7403814103798. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 23.798141390453214. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 3007.1368597727715. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 1114.4478182258474. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1595.3037229239123. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 285.57198768481203. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 331.26400549711184. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 231.2439147585007. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1337.7320401325285. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 316.38882563238207. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 128.58344487140315. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 89.74982025046037. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 273.79462384199604. Mean Length: 500.0\n",
            "Current batch mean is 367.4261692730961\n",
            "----------\n",
            "Run #29. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1161.8760364743944. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1573.827674122417. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 223.82954140764068. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 2165.671490024622. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 3188.3656086262054. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 252.3639186015712. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 869.7807733501409. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 508.84367269104877. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 303.81526222081334. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 179.0972380699048. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 716.9159416977762. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1509.32650712665. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 261.5448102352446. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 267.9369449886532. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2266.8986431552285. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 148.71107469634796. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 266.7948843466223. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 262.01577264424327. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 90.78943728374799. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 279.8552699657328. Mean Length: 500.0\n",
            "Current batch mean is 291.83526609327305\n",
            "----------\n",
            "Run #30. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1685.5081503786416. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 209.1745348548632. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 423.32772246524536. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 284.4001771397154. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 263.17868257739286. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 2117.777387341917. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 297.2889924377523. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 316.51415601764273. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 558.490961847449. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 235.34336164725596. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 225.23274485400373. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 241.82875218181826. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 180.1694137653411. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 322.77350931469744. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 298.13341008338483. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 215.6955257093977. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 230.03663658661898. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1637.3655294193668. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 690.6117615781365. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 237.6852196128013. Mean Length: 500.0\n",
            "Current batch mean is 290.84458478873387\n",
            "----------\n",
            "Run #31. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 373.6017634988427. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 240.705833224366. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 2626.759959398916. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1761.3284923720294. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 234.9985811308845. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 231.8278845069973. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 392.3023337698178. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 758.4948574256466. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 334.014378873773. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1280.8541329024354. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2103.122852297399. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 381.6482581823601. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 228.47953945253343. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 304.01215282121524. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 275.8936528709257. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 131.1333163657572. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1675.9562750475675. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2393.294084022861. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 689.239897507426. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2480.1521283353386. Mean Length: 500.0\n",
            "Current batch mean is 386.97529597608894\n",
            "----------\n",
            "Run #32. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1303.785008912563. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 602.7986315869198. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 406.5220782828024. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 226.57979778459193. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1588.434007765873. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 272.1047916277528. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 636.5976347355187. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1829.3355738490689. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1571.2463968224263. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1553.1294461569112. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 286.7498917044688. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 2486.6092630216867. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 210.94822168185348. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 551.2378486640929. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 288.81511137057015. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1145.3764793214202. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 195.2726149449488. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 200.9139707325854. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 235.36477581476615. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 65.38031188128308. Mean Length: 500.0\n",
            "Current batch mean is 478.8799634734477\n",
            "----------\n",
            "Run #33. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 85.09370935137804. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 269.0710371301433. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 127.64070005086212. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 220.19776901853902. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 644.1118121081695. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 233.19239585069587. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1075.043043747234. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 192.7076990723373. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 209.17032778156792. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 334.6346738032875. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 240.1338104945412. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 824.1790848215827. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 444.90731066485955. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 223.34304591533868. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1021.0780048664698. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 873.7520106628958. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2361.8816421172132. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 318.2907461377594. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2840.4453651393674. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 455.43322903755217. Mean Length: 500.0\n",
            "Current batch mean is 326.46270997052346\n",
            "----------\n",
            "Run #34. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 222.9606040541046. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 241.8816164258235. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 730.355973170275. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 2003.5961774520938. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 249.87936789672224. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 674.1316654899254. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 999.7664418595709. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 274.39801548944627. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1265.2352601609452. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 978.0246532151938. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 568.6071044463573. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1250.2702697176337. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 241.51053775266502. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 575.4530719011179. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 209.09490773355347. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1451.333533926663. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 851.995104339256. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 357.3913314678117. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 682.1962732174887. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 2145.292128238865. Mean Length: 500.0\n",
            "Current batch mean is 678.163969353707\n",
            "----------\n",
            "Run #35. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 275.8816170837032. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 275.15271700932817. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 163.4528873395483. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 325.84545862059326. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1184.250158248777. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1126.214672546139. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 303.3694749601838. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1024.9352342036095. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1575.1260647460965. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 238.6200121326373. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 260.1565847337863. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 283.37601048283835. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 295.53765056383054. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 566.1529391964766. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 334.0280660241193. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1794.7428049314012. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 227.141176178108. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 398.4800066502811. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 240.80259132991824. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 278.53519306723194. Mean Length: 500.0\n",
            "Current batch mean is 299.4535627620072\n",
            "----------\n",
            "Run #36. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 310.12668214091013. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 305.80419874687595. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 686.9275750104429. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 334.7325890887281. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1208.5258560354196. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 3001.014725460271. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 3207.3010220252086. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2678.9121195274042. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2738.1747879657933. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 2608.5104513849724. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 292.3048552522361. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 629.8998665604169. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 270.1711373828924. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1063.2299636996581. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 957.7337773694924. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 166.11618988660703. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 202.62997234277503. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2322.2688547625958. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 384.41389271653856. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 245.02413767751648. Mean Length: 500.0\n",
            "Current batch mean is 658.4137207854299\n",
            "----------\n",
            "Run #37. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 276.68932218743515. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 254.25363300883612. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 679.9099172690246. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 260.18386052108883. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 200.3918034787596. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 721.9310992202037. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 499.1617234038179. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 136.79657782496952. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 246.96985203681382. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 256.3714499316101. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 245.54434144703112. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 148.68292996502223. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 279.231815616928. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1222.749467166615. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2722.4515977540764. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 2025.4389772190202. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 220.5193871569555. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 244.8229269045499. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 141.23945224688708. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 414.31345894386095. Mean Length: 500.0\n",
            "Current batch mean is 258.27765522634945\n",
            "----------\n",
            "Run #38. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 232.13732286131193. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 416.0935825941193. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 209.4441658056379. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1467.3566768744934. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 137.07986073794117. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 317.6692781375912. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 2664.969088598268. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2082.5563328070925. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2558.690859143197. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 1642.0398278959099. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 145.12883583202336. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 430.43716683776137. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 2048.6302304235282. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 258.88561271650997. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2162.5333014557264. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 951.7792341803968. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1599.4538980893421. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 200.2374333194981. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 174.24001219497586. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 251.72992807919962. Mean Length: 500.0\n",
            "Current batch mean is 423.2653747159403\n",
            "----------\n",
            "Run #39. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 798.0798992404958. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 558.8650237494389. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 531.734630683483. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 197.18910100603512. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 424.1310300225555. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 145.80254780309713. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 824.3134926149538. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 352.10000548599174. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 223.1341730666848. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 833.8499221563209. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 153.58056244803868. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 284.94408141140883. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 241.5416975162216. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 268.10468184585767. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 282.3514520284936. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 363.80850890999824. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 270.4216467801435. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 748.1543224993868. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 680.5214260603686. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 647.4618743494837. Mean Length: 500.0\n",
            "Current batch mean is 357.954257197995\n",
            "----------\n",
            "Run #40. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1356.5316805467644. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 150.22211673303133. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1934.7622709007073. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 498.31397800481125. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1720.1867597976443. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 643.227216660742. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 329.34259210248115. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 247.7011809081542. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1744.4822190881505. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 586.9597997719953. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 268.9941942006967. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 176.08201127173405. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 282.7091168565971. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 187.09853587628837. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 237.01153651826718. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 301.5973810358294. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 180.42752500582674. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1900.355052042573. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1185.7332006457668. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 239.28838316989192. Mean Length: 500.0\n",
            "Current batch mean is 315.46998656915525\n",
            "----------\n",
            "Run #41. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 212.24092648892398. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 231.55429739763113. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1402.6588284609004. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 248.6282827598251. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1925.0801551328066. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 712.8696698120827. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 1115.1466726904523. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2249.537287724403. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2421.6335115745906. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 272.55244956306916. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 599.767627170704. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 2233.085772694012. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1074.9719244554603. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2058.6779083043552. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1570.0767422564224. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 189.75062776646928. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 216.2418326468069. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 294.42342969332304. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 90.75480178478243. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1019.897501139357. Mean Length: 500.0\n",
            "Current batch mean is 866.3835854757199\n",
            "----------\n",
            "Run #42. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 278.4895870577773. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 301.12564667460083. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 308.26857072934774. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 71.0471225108456. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 915.6044124183626. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 700.8243292959104. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 284.3489716657934. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 213.834685243142. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 291.97265675253453. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 183.68184351105288. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 375.48584445180256. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 536.6585807753338. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 390.12731838497206. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 246.12128100976793. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 28.74605559613903. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 261.58158984264327. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 260.4018903921213. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 246.65723104658625. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 231.87217145901406. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 248.5902106274008. Mean Length: 500.0\n",
            "Current batch mean is 270.0355884502103\n",
            "----------\n",
            "Run #43. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 263.0008023702632. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 198.6432133470163. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 230.70205738465862. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 244.05557886946875. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 169.8293983742409. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 255.03972865426294. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 261.25998080505076. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 267.61493173360117. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 285.0795650956431. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 487.53282204180726. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 284.0602363969643. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 84.53771694334368. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 241.9220658393883. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 272.99881745366355. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 240.43534265551745. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 283.5692210162363. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 341.3614514009197. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 236.9277112345305. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 235.90278209416275. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 154.7580731737234. Mean Length: 500.0\n",
            "Current batch mean is 249.54765376186583\n",
            "----------\n",
            "Run #44. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 188.26177184644055. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 377.92767475017064. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 275.09996215751704. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 282.6661408364125. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 292.9186905640288. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 331.8007111401793. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 364.75543368374133. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 272.52510332962106. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1331.286319862933. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 170.38791142191693. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 748.666494129094. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 1251.9148189172638. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 892.7332822201096. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 1199.0829602544934. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2089.153434134878. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 472.58351815703486. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 255.6530999189896. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2031.9345804555696. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 164.02156056773654. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 223.6276589365157. Mean Length: 500.0\n",
            "Current batch mean is 348.27807241196035\n",
            "----------\n",
            "Run #45. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 664.5881125024363. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 260.43038432800114. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 603.4388865010814. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 555.5861140101333. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2211.8730276822066. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1741.8769030153305. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 874.3294071012198. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 2495.235839370549. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1981.6913202733397. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 269.160637013031. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 1096.250127634032. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 219.3051753087444. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 1687.881462679037. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 217.96813612016294. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2241.3406643547546. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 780.395940803116. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 2434.6327409857968. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2400.520738915565. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1211.9242886141444. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 182.547473247914. Mean Length: 500.0\n",
            "Current batch mean is 985.2897673676259\n",
            "----------\n",
            "Run #46. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 1793.5568956947238. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 540.9153066076502. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 446.9582232762976. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 1952.2092653635455. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 2049.3876866413757. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 1408.4283447008652. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 2111.050591336749. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 1560.3339258952883. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1395.6838038319884. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 656.7034167835888. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 379.52076007678954. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 204.25239442148873. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 263.42998614865263. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 639.3211600759256. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 529.6826333060503. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 257.9245798028974. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1779.0162530795778. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2021.395709599728. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 2388.1020294627215. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 1208.8803214832658. Mean Length: 500.0\n",
            "Current batch mean is 1302.2820626576272\n",
            "----------\n",
            "Run #47. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 225.58573034584563. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 1639.8891119956231. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 1595.8289686325443. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 761.9552471511513. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 185.13078514593846. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 349.2979468299144. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 667.4082798027126. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 493.8280401627556. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 887.9772310319026. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 186.34998763337418. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 249.05416058615083. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 214.75482922659083. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 885.4103189824557. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 317.4596441958678. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 189.7369845936821. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1979.967997048355. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 203.1427106133678. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 1230.5054135690245. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 1841.2369604942508. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 516.3028345436564. Mean Length: 500.0\n",
            "Current batch mean is 505.065437353206\n",
            "----------\n",
            "Run #48. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 3368.1011043202116. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 241.15032774468634. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 2315.37769104371. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 601.8016548946874. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 1020.0155066917815. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 214.97217065422436. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 235.10420465608806. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 239.1565420472777. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 2184.202727886102. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 849.0871983494209. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2346.3969382430782. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 243.4251068681025. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 496.5982447871744. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 2702.2779805753144. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 2373.690484083383. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 388.0075018410139. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1225.4720393376228. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 2074.1446133540276. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 110.03599853475207. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 279.26385368442965. Mean Length: 500.0\n",
            "Current batch mean is 725.4444266220542\n",
            "----------\n",
            "Run #49. The \"+9\" threshold is 0.003\n",
            "starting training with 20 epochs\n",
            " Epoch: 1. Mean Return: 132.489964661909. Mean Length: 500.0\n",
            " Epoch: 2. Mean Return: 211.36075998555705. Mean Length: 500.0\n",
            " Epoch: 3. Mean Return: 212.03774969037838. Mean Length: 500.0\n",
            " Epoch: 4. Mean Return: 259.385495083217. Mean Length: 500.0\n",
            " Epoch: 5. Mean Return: 261.8746856753865. Mean Length: 500.0\n",
            " Epoch: 6. Mean Return: 231.2188419172934. Mean Length: 500.0\n",
            " Epoch: 7. Mean Return: 211.7039204747129. Mean Length: 500.0\n",
            " Epoch: 8. Mean Return: 223.8821940692385. Mean Length: 500.0\n",
            " Epoch: 9. Mean Return: 1922.615218293832. Mean Length: 500.0\n",
            " Epoch: 10. Mean Return: 453.4374660258055. Mean Length: 500.0\n",
            " Epoch: 11. Mean Return: 2986.8525229868114. Mean Length: 500.0\n",
            " Epoch: 12. Mean Return: 168.64331579303087. Mean Length: 500.0\n",
            " Epoch: 13. Mean Return: 219.87895892804985. Mean Length: 500.0\n",
            " Epoch: 14. Mean Return: 885.1082543663547. Mean Length: 500.0\n",
            " Epoch: 15. Mean Return: 1238.2706804301636. Mean Length: 500.0\n",
            " Epoch: 16. Mean Return: 1700.2959951980854. Mean Length: 500.0\n",
            " Epoch: 17. Mean Return: 1919.1230644567697. Mean Length: 500.0\n",
            " Epoch: 18. Mean Return: 236.71389701163022. Mean Length: 500.0\n",
            " Epoch: 19. Mean Return: 218.95506333396602. Mean Length: 500.0\n",
            " Epoch: 20. Mean Return: 263.93900706790225. Mean Length: 500.0\n",
            "Current batch mean is 248.0496960474236\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjmClmacRP9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0193725-293a-49ea-98f3-9df1641ce747"
      },
      "source": [
        "observation = env.reset()\n",
        "episode_return = 0\n",
        "# Iterate over the steps of each epoch\n",
        "for t in range(steps_per_epoch):\n",
        "    if render:\n",
        "        env.render()\n",
        "\n",
        "    # Get the logits, action, and take one step in the environment\n",
        "    observation = observation.reshape(1, -1)\n",
        "    logits, action = sample_action(observation)\n",
        "    #print(type(action[0].numpy()))\n",
        "    observation_new, reward, done, info = env.step(action[0].numpy())\n",
        "    episode_return += reward\n",
        "\n",
        "    # Update the observation\n",
        "    observation = observation_new\n",
        "print(episode_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4250.679984177324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "MrSJapY0QMDX",
        "outputId": "f6d36e9a-360c-40c2-a544-56fece2fb2b1"
      },
      "source": [
        "x = np.array(info['x'])\n",
        "t = np.array(info['t'])\n",
        "roll, pitch, yaw = quat2rpy_deg(x[:,0], x[:,1], x[:,2], x[:,3])\n",
        "size = roll.shape[0]//3\n",
        "print(np.mean(roll[-size:]))\n",
        "print(np.mean(pitch[-size:]))\n",
        "print(np.mean(yaw[-size:]))\n",
        "print(np.std(roll[-size:]))\n",
        "print(np.std(pitch[-size:]))\n",
        "print(np.std(yaw[-size:]))\n",
        "\n",
        "plot_euler_angles(t, roll, pitch, yaw, 'angles2.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.16846294371698603\n",
            "-0.30325245506908854\n",
            "-0.21673140167288255\n",
            "0.06841219338229675\n",
            "0.05587308062379423\n",
            "0.06644251803935496\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsbZBb30IwPX"
      },
      "source": [
        "start = x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Md87ci725AIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8abmL43pFlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c7cc5aae-c6b9-48d1-b0da-3292134c335e"
      },
      "source": [
        "actor_config = actor.get_config()\n",
        "actor_weights = actor.get_weights()\n",
        "critic_config = critic.get_config()\n",
        "critic_weights = critic.get_weights()\n",
        "import pickle\n",
        "name = f'configs_weights {iterations} {reward_thresh}.pickle'\n",
        "with open(name, 'wb') as f:\n",
        "  pickle.dump((actor_config, actor_weights, critic_config, critic_weights), f)\n",
        "from google.colab import files\n",
        "files.download(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fcedfd95-0f89-42af-af66-8d711436fb28\", \"configs_weights 20 0.003.pickle\", 1168930)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p3CM-9IM5MX"
      },
      "source": [
        "import pickle\n",
        "\n",
        "name = f'configs_weights(original,th=0.004).pickle'\n",
        "with open(name, 'rb') as f:\n",
        "  something = pickle.load(f)\n",
        "\n",
        "actor_config, actor_weights ,critic_config, critic_weights = something\n",
        "actor = keras.Model.from_config(actor_config)\n",
        "actor.set_weights(actor_weights)\n",
        "critic = keras.Model.from_config(critic_config)\n",
        "critic.set_weights(critic_weights)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}